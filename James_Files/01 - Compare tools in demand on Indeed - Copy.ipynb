{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing things\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = pd.read_csv('./Resources/01_indeed_job_dataset.csv')\n",
    "df01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01= df01[['Queried_Salary','Job_Type','Company_Industry','python','sql','machine learning','r','hadoop','tableau','sas','spark','java','Others','CA','NY','VA','TX','MA','IL','WA','MD','DC','NC','Other_states','Consulting and Business Services','Internet and Software','Banks and Financial Services','Health Care','Insurance','Other_industries']]\n",
    "df01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyst_frame = df01.loc[df01['Job_Type']=='data_analyst']\n",
    "analyst_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "python_count= analyst_frame.python.sum()\n",
    "r_count= analyst_frame.r.sum()\n",
    "hadoop_count= analyst_frame.hadoop.sum()\n",
    "tableau_count= analyst_frame.tableau.sum()\n",
    "sas_count= analyst_frame.sas.sum()\n",
    "spark_count= analyst_frame.spark.sum()\n",
    "java_count= analyst_frame.java.sum()\n",
    "sql_count= analyst_frame.sql.sum()\n",
    "\n",
    "print(f'{python_count} {r_count} {hadoop_count} {tableau_count} {sas_count} {spark_count} {java_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax01 = plt.subplots(figsize=(12, 12))\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "ax01.bar(['Python', 'R', 'SQL','Hadoop', 'Tableau', 'SAS', 'Spark', 'Java'], [python_count,sql_count,r_count,hadoop_count,tableau_count,sas_count,spark_count,java_count])\n",
    "ax01.set_title(\"Skills in Demand (2018, Indeed)\")\n",
    "ax01.set_ylabel(\"Appearances in Data Analyst Jobs\")\n",
    "ax01.set_xlabel(\"Common Skills\")\n",
    "ax01.annotate(python_count,xy=(-.25,python_count))\n",
    "ax01.annotate(sql_count,xy=(.75,sql_count))\n",
    "ax01.annotate(r_count,xy=(1.75,r_count))\n",
    "ax01.annotate(hadoop_count,xy=(2.75,hadoop_count))\n",
    "ax01.annotate(tableau_count,xy=(3.75,tableau_count))\n",
    "ax01.annotate(sas_count,xy=(4.75,sas_count))\n",
    "ax01.annotate(spark_count,xy=(5.75,spark_count))\n",
    "ax01.annotate(java_count,xy=(6.75,java_count))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('./Graphs/Skills_In_Demand_Indeed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
